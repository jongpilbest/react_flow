// app/api/chat/route.ts

import { NextResponse } from 'next/server';

export async function POST(req) {
  const { Node ,input_result ,dummy} = await req.json(); // í”„ë¡ íŠ¸ì—ì„œ ë³´ë‚¸ ì‚¬ìš©ì ë©”ì‹œì§€ ë°›ê¸°

  const openaiRes = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
    },
    body: JSON.stringify({
        model: 'gpt-4o', // ë˜ëŠ” 'gpt-4', 'gpt-3.5-turbo'
        messages: [
          {
            role: 'system',
            content: `ë‹¹ì‹ ì€ ì¹œì ˆí•œ SQL ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ${dummy} ë°ì´í„°ë¥¼ í™œìš©í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš” ì ì ˆí•œ ì˜ˆì‹œë¥¼ ì•Œì•Œë ¤ì£¼ì„¸ìš”.  `,
  
          },
          {
            role: 'user',
            content: `ë‹¤ìŒì€ SQL ì¿¼ë¦¬ íŠ¸ë¦¬ì…ë‹ˆë‹¤:\n${JSON.stringify(Node, null, 2)}\n\nì‚¬ìš©ìì˜ í˜„ì¬ ì¿¼ë¦¬ëŠ” :\n${sql} ë”ë¯¸ë°ì´í„°ëŠ” ${dummy}ì…ë‹ˆë‹¤.`,
          },
        ],
        temperature: 0.5,
        stream: true, // ğŸ”¥ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìš”ì²­
      }),
  });

  // OpenAI ì‘ë‹µ ìŠ¤íŠ¸ë¦¼ì„ ê·¸ëŒ€ë¡œ í”„ë¡ íŠ¸ë¡œ ì „ë‹¬
  const stream = openaiRes.body;

  return new NextResponse(stream, {
    headers: {
      'Content-Type': 'text/event-stream', // ìŠ¤íŠ¸ë¦¬ë°
      'Cache-Control': 'no-cache',
      'Connection': 'keep-alive',
      'Transfer-Encoding': 'chunked',
    },
  });
}




